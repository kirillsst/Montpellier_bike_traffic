# train_model/pipeline.py
import logging

# Import des modules locaux
import loader
import trainer
import evaluator
import saver

# Config Logs
logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger()

def run_training_pipeline():
    logger.info("üöÄ D√âMARRAGE DU PIPELINE D'ENTRA√éNEMENT")

    # 1. Chargement global
    df_global = loader.load_full_dataset()
    compteurs = df_global['name'].unique()
    
    results = []

    # 2. Boucle sur chaque compteur
    for name in compteurs:
        logger.info(f"üîπ Traitement : {name}")
        
        # A. Pr√©paration des donn√©es
        train_df, test_df = loader.get_data_for_counter(df_global, name)
        
        if test_df.empty:
            logger.warning(f"   ‚ö†Ô∏è Pas de donn√©es de test pour {name}. Ignor√©.")
            continue

        # B. Entra√Ænement
        model = trainer.train_model(train_df)

        # C. Pr√©diction (Test)
        forecast = trainer.make_predictions(model, test_df)

        # D. √âvaluation
        mae, error_pct = evaluator.evaluate(test_df, forecast)
        logger.info(f"   üìä Score : MAE={mae} | Err={error_pct}%")

        # E. Sauvegarde Mod√®le
        model_file = saver.save_model(model, name)

        # Stockage des r√©sultats
        results.append({
            "Compteur": name,
            "MAE": mae,
            "Erreur %": error_pct,
            "Fichier": model_file
        })

    # 3. Sauvegarde finale des scores
    saver.save_metrics(results)
    logger.info("üéâ Pipeline termin√© avec succ√®s.")

if __name__ == "__main__":
    run_training_pipeline()